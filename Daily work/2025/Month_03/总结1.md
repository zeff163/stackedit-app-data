

## 三月总结
### Markdown使用  


### GitHub使用  


### 网页、app等图片获取方法
目前可使用的工具有浏览器脚本、kb、IDM+、小米传送门、f12获取网页信息，各类网站等。具体参考[3.21](../Month_03/21.md)日内容
+ b站 ：利用kb提取封面，或者用Downkyi获取封面。
+ p站图片：
	+ 在app内可以直接保存到本地，或者用传送门（适合简单少量操作）；
	+ 在网页版用X浏览器的p站批量下载脚本，获取当前页面所有插图的下载直链（可能需要退出当前页面后，才会出现下载直链的页面），然后保存到可乐记中导出txt文件，再用IDM+下载（适合大量图片的提取）

+ p站小说：	
	+ 使用powerful pixiv download，使用方式见 <a id ="01-1">[<font color=red>备注1</font>](#01-2)（一般用于批量下载系列页、个人主页小说）
	+ 使用X浏览器中的pixiv小说下载器插件（一般用于下载收藏页的零散小说）

	注：为什么pixiv的小说无法用插件抓取外链并使用外部下载器下载例如idm+，而插图可以？[回答](https://github.com/xuejianxianzun/PixivBatchDownloader/issues/307)

+ 贴吧：直接下载或者传送门
+ twitter网页：使用脚本【Twitter 数据导出工具】下载，具体使用参考 <a id ="02-1">[**<font color=red>备注2</font>**](#02-2)

+ twitter图片：直接保存，或者kb  
+ 淘宝：app内可以用传送门；或者在网页端打开，在浏览器里面下载图片或f12抓取。
+ tt网：直接下载（适合少量）；用f12模式抓取，或者kb（适合批量）
+ e-hentai：这个网站的图片都是用代码嵌入的，不会再网页中放入图片，必须要点开图片才能获得图片。因此使用浏览器脚本或者f12直接获取图片的话，只会得到一张很长的图片集。想要获得图片有以下两种方式：
	+ f12抓取图片所在的代码区，然后用deepseek分离其中图片外链，然后排序复制到可乐记，导出txt文件。再利用idm+的浏览器逐个识别txt文件中的外链进行下载。
	+ 在kb打开网址，然后逐个点开图片，kb会自动嗅探到页面里的图片，等把所有图片点完之后，就会把所有图片都嗅探到，然后统一批量下载就好了。
		注1：可能部分图片没有嗅探到，注意检查，然后重新操作。
		注2：这种方式下载的文件名是很杂乱的，需要对着原漫画进行重命名排版。建议先下载，然后传到电脑里面重命名，因为电脑里面可以预览图片，而且重命名操作方便。
		注3：要区别和n-hentai下载方式的不同，这种是全部提取后下载，而n-hentai则是嗅探后逐个下载。
+ n-hentai：n-hentai的图片都会存在网页中，所以可以
	+ 用f12抓取（但需要逐个图片另存为下载，比较麻烦）；
	+ 用X浏览器中关于n-hentai的脚本抓取（快速但可能出错）
	<font color =red>**补充：脚本抓取错误是由于识别图片的地址出了问题。**<br> 以【图片全载 - FancyboxV5】脚本为例：100多张图片可能只能正确的识别几十张，导出识别的图址，识别错误的图片显示为`https://i.nhentai.net/galleries/3440940/1.webp`；而识别正确的图片地址是`https://i3.nhentai.net/galleries/3440940/2.webp`.因此把前缀改一下就可以正常下载了。</font>
	+ 用kb打开页面，然后点开图片逐个嗅探后下载（注意：kb在这个网站嗅探完所有图片页后，只会保存少量图片的嗅探链接，所以最好一边嗅探一边下载）。
+ 一些漫画网站，例如香香网：用X浏览器脚本批量抓取

### 网页、app等视频获取方法 
目前可使用的工具有kb、IDM+、浏览器资源嗅探、应用程序、各类网站等。
+ 贴吧视频 
	+ 一般的视频：用kb下载
	+ 广告视频：在ES浏览器中data里面找到相应的.seg文件，然后改后缀成.mp4，用kb把H.265改为H.264编码。 
+ B站视频：
	+ 用kb下载或者Downkyi下载（均只能单个下载）
	+ 对于想要下载某up的所有上传视频，则可以在kb里面逐个下载；或者获取每个视频页的链接后，合并成txt文件，再用idm+逐个嗅探（比较麻烦，不太推荐）。
+ Twitter视频：kb或者twitter下载页或者idm+嗅探 https://twitterfk.com/zh-cn/
https://tweeload.com/	
	> <font color = o> 注意：有时候twitter里面一个帖子包含多个视频，如果直接用kb的【短视频无水印下载】功能只能嗅探到一个。~~如果用kb的【网页资源嗅探】，则可以嗅探到所有视频资源，但是下载的视频没有声音。
	这时候可以把嗅探到的视频链接复制下来，然后再去idm+中下载，即可完美下载。~~（这个功能已经不能用了，因为kb的浏览器无法打开twitter网页版了）</font>
	
	更新1：使用脚本【Twitter 媒体下载】([来源](https://greasyfork.org/zh-CN/scripts/529453-twitter-x-media-downloader)) 可以在X浏览器上一键下载（包括多视频的帖子）
	
	更新2：使用脚本【Twitter 数据导出工具】([来源](https://greasyfork.org/zh-CN/scripts/492218-twitter-web-exporter))可以在电脑上批量下载，使用方式参考 <a id ="03-1">[**<font color=red>备注3</font>**](#03-2)
	
	<font color=red>注：这两个脚本均无法抓取帖子是通过网站来分享的视频，想抓取这种点击后回跳到网站的视频，只能用上面给的两个网站去获取。

+ 淘宝视频：
	+  ~~获取页面链接，kb下载或者浏览器资源嗅探。~~（该方法有的视频无法下载）
	+ 完整播放完视频后，用ES文件管理器在data中寻找下载。
+ 微信公众号视频：用`E:\wechatvideodownload` 应用下载，注意用kb转换为H.264编码。


---
### 备注
1.  脚本【Poweful Pixiv Downloader】介绍
	**插件的来源**
	安卓端：https://www.chajianxw.com/photos/12829.html
	pc端：https://github.com/xuejianxianzun/PixivBatchDownloader

	**官方教程**
	 https://xuejianxianzun.github.io/PBDWiki/#/ 
	下面主要说明使用的流程和发现的问题：	
	
	**下载器配置**
	抓取
	 + 抓取多少页面 （建议为-1）
		> 这个主要是用于对包含多页内容的抓取，例如收藏页、个人主页等。如果设为5，则是从当前页面出发往后抓取5页。默认为-1，即当前页面后的所有页面
		><font color =red>注：这一栏不会出现在单独的作品页中，如果出现，请刷新网页，否则抓取会出现错误</font>
	
	+ 抓取多少作品 （建议为1）
		> 和上面不同，这个只会出现在单独的作品页之中，例如：一篇小说、一些插图。如果设为1，则是只抓取一个文件，如果是5，而且选择【抓取新作品】，那么就会下载从该作品出发，按作品id排序，该页面内的包含的最近5件作品（页面包含的作品在文件底部作者栏下面可以看到）。如果设为-1，那么会下载从该文件出发，该作者所有新发布的作品
	
	+ 作品类型 （根据下载内容勾选）
		> 勾选插画：则只抓取插画；勾选小说：则只抓取小说；其他类似

	+ 年龄限制、AI作品、收藏状态、图片色彩、图片数量 （建议全点）
		> 勾选哪一项就会允许抓取该项的内容，不勾选则不会抓取这些内容。

	+ 显示高级设置 （建议打开）
		> 可以更精细的调整抓取内容
	
	+ ID范围 （根据需要设置，默认为0）
		>通过设置数值，在当前页面进行筛选，不符合ID要求的内容不会抓取

	+ 投稿时间 （根据需要设置，默认不打开）
		>通过设置数值，在当前页面进行筛选，抓取在设定的投稿日期区间内的作品。	

	下载	
	+ 命名规则 
		> 小说：
		> 个人主页：{user}/{user}_{id}_{title}   作者/作者_作品id_文件名
		> 效果：一水东流/一水东流_23497513_骚狗英雄黑耀沦陷.txt
		>
		> 系列页：{series_title}/{series_title}_{id}_{series_order}_{title}  系列/系列名_作品id_系列编号_文件名
		> 效果：首领黑耀的败北恶堕/首领黑耀的败北恶堕_23497513_#1_骚狗英雄黑耀沦陷.txt
		>
		> 单独的作品页：pixiv/{title}_{user}_{id}  pixiv/文件名_作者_作品id
		> 效果：pixiv/首领黑耀的败北恶堕_一水东流_23497513
		>
		> <font color =red>注：在安卓内浏览器是没有权限创建文件夹的，所有文件全部都会下载到Download文件夹中</font>

	+ 在不同的页面类型中使用不同的命名规则 （必须打开）
		> 针对不同的页面，例如【个人主页】、【系列页】会保存各自的文件命名方式，如果关闭，所有文件下载的文件名格式都一样。

	+ 只有一个抓取结果时不建立文件夹 （建议关闭）
		> 这个功能的用处：只在抓取的页面是【作品页】，而且已经在【抓取多少作品】中设置数值为1时，才有效果。

	+ 同时下载数量 （建议设为5）
		> 影响下载进度中可以看到的下载个数
	
	+ 自动开始下载 （必须关闭）
		> 一律建议在浏览完抓取内容和文件名后再手动点击【开始下载】

	+ 把文件保存到用户上次选择的位置  （建议关闭）
		> 这个功能是在电脑中指定下载到某个文件夹内，而不是浏览器默认文件夹时才有用。缺点在于，每次下载都会询问，如果有100多个文件下载，那要手动点击100多次，所以不如直接后台下载到默认文件夹。

	更多 	
	+ 抓取 —— 减慢抓取速度 （建议上限100-150）
		> 对于文件较多时，如果一次性全部抓取，会导致409错误，所以超过某个上限时，需要每隔一件作品间隔一段时间抓取。曾经设置200时，出现报错。

	+ 命名 —— 在序号前面填充 0 （建议打开，长度设为3）
		> 这个用于对很多图片进行整齐排序，尤其是安卓会出现p10排在p2前导致混乱。

	+ 下载 —— 自动合并系列小说 （建议关闭）
		> 如果开启，那么在系列页抓取完成后，会自动下载合并后的小说，无法在下载处点击【开始下载】来调控。如果需要合并，可以直接在抓取页面处点击【抓取合并小说】，然后手动下载。

	+ 下载 —— 在小说里保存元数据 （建议打开）
		> 可以在下载的小说中添加作品的各类信息（作者、发布时间、标签、简介等）
	
	+ 下载 —— 下载小说的封面图片 （建议关闭）
		> 会单独下载图片，因为文本保存为txt，不好管理。
	
	+ 下载 —— 下载小说里的内嵌图片 （建议关闭）
		> 会单独下载图片，因为文本保存为txt，不好管理。

	+ 下载 —— 保存作品的元数据 （建议关闭）
		> 不如直接保存到小说中方便，而且会多很多无效文件，不便于管理

	+ 下载 —— 文件下载顺序 （建议按作品ID排序）
		> 会影响在下载处【浏览文件名】的排序，按ID排序可以更好的检查是否有文件遗漏 

	+ 下载 ——  不下载重复文件（建议关闭）
		> 打开后所有已下载过的内容均不会再下载（这个历史记录会保存在浏览器中，除非清除浏览器数据，否则无法删掉）。可以用来下载作者发布的新作品。

	+ 其他 —— 选项卡切换方式 （必须选鼠标点击）
		> 防止鼠标误滑增加操作


	**操作流程**
	1. 文件抓取
		对于小说页面，主要是在【收藏页】、【个人主页】、【系列页】、【作品页】这四种页面中抓取，<font color=red>**而这四种页面的抓取提示应该是不一样的。**</font> 例如：收藏页面的抓取按钮会变成【开始抓取】；系列页则是【抓取系列小说】。
<font color =red>**注：请务必小心自己抓取的提示页面是否和当前页面一致，否则会出现抓取混乱。（这个问题在安卓中不太会遇到，但是在pc端会经常遇到，尤其是点击到另一个页面类型后，抓取的模式并未切换，解决方式就是刷新界面）**</font>

		在确认抓取页面和抓取模式一致后，可以点击抓取按钮，顶部会出现【显示日志】，可以看到抓取进度，对于抓取大量内容需要有时间间隔的，可以预估所需时间。（ps：个人感觉安卓端比pc端抓取速度更快）
**抓取个人主页、系列页时**，可以设置抓取页面数为-1，那么会抓取所有的内容，也可以指定抓取的页面数。
**抓取单独的作品页时**，如果设置抓取数为1，那么只抓取该作品，；如果设为-1，且选择【抓取所有新作品】，那么会抓取该作品之后，作者发布的所有作品。此外还可以选择抓取该作品的相关作品页，参考官方教程。

	2. 文件下载
抓取完成后，确认好命名规则，就可以点击【预览文件名】来检查数量和内容是否无误，之后就可以点击【开始下载】。
**在安卓端**，所有下载全部都保存到Download里面，既不能创建文件夹，也不能选择每个文件的下载目录。
**在pc端**，如果在浏览器的下载管理中设置了【下载前询问保存位置】，那么每个文件在下载时都会出来弹窗确定下载目录。这样做可控性更强，但如果要下载很多内容时，每条下载记录都要手动确认，就会很麻烦，所以建议下载时【开启静默下载】，统一下载到浏览器默认下载目录中。

	3. 文件保存
		下载完成后会得到一堆txt文件，根据需要上传到telegram中。
		如果采用安卓上传，由于内容全部都是下载到Download里面，所以会很难找，可以在顶部标签使用【最近】&【文档】来进行筛选。但是这样最多只会出现24个文件，超出数量的文件则无法搜索出来。因此对于更多数量的文件建议在电脑上操作，把Download里面的上传文件转移到文件中转站中，然后直接在文件中转站里全选上传。

		目前telegram分类主要是【收藏页】、【个人主页】、【系列页】这三个大类。
		【收藏页】放在群组【pixiv收藏夹】的【小说】话题中，这个主要是用X浏览器的【Pixiv小说下载器】插件下载。
【个人主页】、【系列页】放在频道【p站小说】中，每个作者的主页和他的部分系列页都会有一个单独的对话，所有文件放在评论中，便于后续增减。
<font color = red>**文件的查找建议根据作者名搜索，每次新增的作者，需要在置顶栏中添加。**</font>

	4. 更新
	对于已添加的内容有了更新，可以采用以下三种方式来下载新内容：  		  
	+ 不下载重复文件
	在新增的页面中进行抓取，并在【更多】-- 【下载】处点击【不下载重复文件】来避免重复下载旧的内容。所有页面均可适用，但只能用一次，不太推荐。
	+ 按ID抓取
	找到最近的已保存内容的ID，然后在抓取时设置ID范围，避免抓取旧的内容。这个一般是在【个人主页】、【系列页】中抓取时使用，比较推荐。
	+ 抓取新发布的作品
	进入到单独的作品页，然后点击【抓取新发布的作品】，之后插件就会抓取该作品之后作者发布的所有内容。只能用于【作品页】，且会抓取作者的所有作品，无法指定某系列的内容，不太推荐。

	<a id ="01-2"> [<font color = red>跳回</font>](#01-1) 

2. 脚本【Twitter 数据导出工具】介绍
在浏览器打开网页版twitter后，如果该脚本开启，那么它会在后台自动抓取内容。根据抓取的页面主要分为以下5个：
+ 书签
	当打开书签页时开始捕捉，捕捉的内容为书签页展示的主帖内容。帖子内的内容不捕捉。
+ 喜欢
	当打开个人喜欢页时开始捕捉，捕捉的内容为喜欢页展示的主帖内容。帖子内的内容不捕捉。
+ 用户推文
	当打开某个推特用户的个人主页时开始捕捉，捕捉的内容为该主页展示的主帖内容。帖子内的内容不捕捉。
+ 用户媒体
	当打开某个推特用户的个人媒体页时开始捕捉，捕捉的内容为该媒体页展示的媒体。帖子内的内容不捕捉。
+ 推文详情
	当打开某个具体的帖子时开始捕捉，捕捉的内容为该帖子的所有回复。如果回复内还有回复，需要展开回复进行抓取。
	
	注1：由于推特页面是懒加载的机制，所以需要手动下滑网页来让脚本抓取全部内容。如果需要自动化移动页面，需要配合脚本，参考脚本[来源](https://greasyfork.org/zh-CN/scripts/492218-twitter-web-exporter)处的使用说明。
	
	注2：进入新页面时，捕捉的内容不会主动删掉，而是会叠加，按照发帖的时间顺序进行排列。如果觉得捕捉内容不好，想重新捕捉，需要手动在捕捉信息页面左下角进行清除，然后再进入该页面捕捉。

3. 使用脚本【Twitter 数据导出工具】实现页面获取

4. 使用脚本【Twitter 数据导出工具】实现视频的批量下载 

<!--stackedit_data:
eyJoaXN0b3J5IjpbLTIxMjExNjczNSwtODU5NDExMzc1LDE0MD
I0NzE0ODksMTk5MjEyNDE2Nyw0OTkzNzI0MDUsMjc3MzE4NTM1
LDE4NjEwNjgwODQsLTEyNjM4NTU3MTMsMTkxMDk5OTAyMywtMT
I1OTU0NTA1OSwtODY4OTQ2NDYwXX0=
-->