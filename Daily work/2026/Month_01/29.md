## <font color = blue face=楷体 size=6>日期 1.29 </font>

## <font color = green>知识学习 </font>
### <font color = purple>专业知识 </font>
+ <a id = "01-1">  [<font color = red>跳转</font>](#01-2)
   > <font color = o> 说明 </font>
### <font color = purple>生活常识 </font>

### <font color = purple>求职 </font>



## <font color = green>心得 </font>
### <font color = purple>学习心得 </font>
+ 
### <font color = purple>生活技巧 </font>

### <font color = purple>Good Idea </font>



## <font color = green>新名词 </font>
### <font color = purple>英文单词 </font>
### <font color = purple>新词 </font>



## <font color = green>各类网站 </font>


## <font color = green>资源文件 </font>


## <font color = green>新闻 </font>


## <font color = green>新知 </font>
+ 

## <font color = green>待办事项 </font>
### <font color = purple>事项 </font>
- [ ] ...
### <font color = purple>已解决 </font>
### <font color = purple>疑问 </font>
- [ ] ...
### <font color = purple>明日计划 </font>
- [ ] ...


## <font color = green>备注 </font>
  1. <a id ="01-2">[<font color = red>跳回</font>](#01-1)


一般网站可以加入的后缀
subscribe 订阅
https://bewildcard.com/ -> https://bewildcard.com/subscribe
tutorial 教程
https://bewildcard.com/ -> https://bewildcard.com/tutorial
service 服务
https://bewildcard.com/ -> https://bewildcard.com/service

可以加入的前缀
help 帮助
https://bewildcard.com/ -> https://help.bewildcard.com/ 

open ai paltform：[Migrate to the Responses API | OpenAI API](https://platform.openai.com/docs/guides/migrate-to-responses)


groq

gpts api：
https://api2.gptsapi.net/tutorial

langchain
https://mp.weixin.qq.com/s/E-P7qZquMSPYYfg7yvGm9Q

moltbot
https://waytoagi.feishu.cn/wiki/Bi3HwfqPcibKzGk1yHlcg3KSnwd
> manus

Windows系统Claude Code小白安装教程
https://waytoagi.feishu.cn/wiki/LUQTwefK0iPCiGkaOylcLoVPngg


1. agent 工具
langchain：它提供模块化的组件（如Chain链、Agent代理、Memory记忆、Tools工具），需要用户编写代码来组合它们。
Q：这些组件具体有什么作用？
Q：angchain的这套框架是不是不仅仅用来开发AI工具？

2. 工作流自动化
Q：n8n自托管配置方式

3. LLM模型本地部署工具
【个人理解】：可以看成一个本地的deepseek，例如在coze中构建智能体时，需要使用deepseek的推理功能，一般都是直接在coze中配置模型，这种方式实际上会在使用中调用deepseek官方的api。但如果本地化了deepseek，则可以直接调用自己的api实现。除此之外还可以对本地的模型进行知识库增加，扩展rag嵌入等功能。

	这些工具专注于推理（Inference）：加载已训练好的模型权重，高效生成输出。
Q：什么是模型权重，是模型版本吗？
Q：相比普通的各平台chatbot，这种方式高效在什么地方，是因为所有操作都在本地，没有云端传输的降速吗？但对同样一个问题的回答，会不会由于平台自带LLM之外的功能优化（例如：搜索添加的contex上下文更丰富）使得回答比本地生成的更好？

	Ollama：一键CLI+广泛兼容（包括实验代理循环、Anthropic API模拟），2026年桌面App最用户友好。
Q：什么是Anthropic API模拟？

4. API聚合平台
智能分发请求到最佳提供商，支持模型切换、负载均衡、故障转移等。核心定位是简化多模型开发：开发者无需管理多个API key、兼容不同SDK，适合需要灵活切换模型、优化成本/性能的生产应用。
Q：为什么openrouter的api统一管理会更高效，他是如何兼容不同的SDK？是应用内部实现了不同的平台的转换吗？
Q：智能分发是什么意思？难道在使用时不是指定了api的类型而是平台自动分配的吗？

5. AI聊天客户端
核心定位是生产力前端：美观、扩展性强、隐私友好，适合日常深度使用、模型比较、自定义工作流.
Q：这个工作流制定是不是和agent开发工具coze是一样的？

	这些可本地运行模型或用key控制。
Q：那这和LLM部署工具的本地运行与api调用有什么区别？
Q：如果本地通过ollama部署了一款LLM，那可以在本地通过cherry studio调用该模型的api实现LLM的使用吗？那和直接把LLM部署到cherry studio中有什么区别？

6. AI代码助手
核心定位是提升生产力：从被动补全（inline suggestions）到主动代理（自主规划/执行任务）。典型功能包括：上下文感知补全、聊天侧边栏、Agent模式（多步任务）、测试生成、调试修复。
2026年，这一类快速发展，代理式（Agentic）工具主导，能自主操作文件/终端，而非仅生成文本。
【个人理解】：代理可以理解为代替人执行具体的操作。
和回答问题不一样，向chatgpt要求写一个程序，它可以编出代码，但之后的复制粘贴、调试运行、打包发布等则均需要个人自己的手动操作。
而主动代理则会实现上面的所有功能，完全代替用户执行具体的操作。

	使用：CLI运行claude-code命令，输入自然语言任务（如“调试这个Python脚本”）；它规划步骤、编辑文件、执行命令、迭代直到完成。支持MCP工具权限、浏览器集成。
Q：Claude code如何通过CLI实现MCP调用？有哪些AI应用也能实现这些功能？浏览器集成是什么？

	使用：API调用或平台内（如OpenAI Playground）
Q：如何在Open AI Playground中使用codex？


7. AI代理工具
2026年，这一类快速发展，强调“行动而非答案”
【个人理解】：Manus有点类似coze的task模式，即给一个任务，它会自动执行，但是效果可能不好。但manus和agent的区别是：可使用工具种类的多少。
例如自己开发了一个agent，但其中只嵌入了头条搜索插件，那么如果让这个agent抓取搜索的页面则是无法实现的，因为他没有抓取的插件。所以agent的功能单一，当manus则有更多的功能，因为它有更多的工具可以调用，尽管它们的思考模型是一样的。
【个人理解】：moltbot更像一个AI手机，因为它24h工作，具有操控屏幕和键盘的高级权限。通常为异步操作，即它的行为不一定是及时响应的，往往是后台操作，例如：后台监控邮箱的邮件接收。


8. AI搜索引擎与研究工具
Gemini（Google）多模态强（图像/视频集成Google生态），但搜索有时更泛化、引用不透明。
深度研究选Perplexity；多模态选Gemini；coding选Phind；隐私选AnythingLLM。

上述哪些应用支持本地模型（本地ollama部署）？



stackedit和github在对接时，数据是否会经过stackedit的第三方服务器中？
<!--stackedit_data:
eyJoaXN0b3J5IjpbLTIxMjQ5Mjk4OTUsLTE5Njk0NTQ2NDAsLT
k4NjI1MzMxMiwtMzY4OTQwMTQ0LDE5OTU0NzYyOTFdfQ==
-->