## <font color = blue face=楷体 size=6>日期 4.22 </font>

## <font color = green>知识学习 </font>
### <font color = purple>专业知识 </font>
+ 
   > <font color = o> 说明 </font>
### <font color = purple>生活常识 </font>

### <font color = purple>求职 </font>



## <font color = green>心得 </font>
### <font color = purple>学习心得 </font>
+ 
### <font color = purple>生活技巧 </font>

### <font color = purple>Good Idea </font>



## <font color = green>新名词 </font>
### <font color = purple>英文单词 </font>
### <font color = purple>新词 </font> 
+ **MCP sever：被动的工具箱** 
MCP Server（Model Context Protocol Server）是一种基于标准化协议的服务端程序，主要为大语言模型（LLM）提供外部数据和能力支持。例如，Fetch MCP Server可以抓取网页内容，Google Drive MCP Server可以读取文件。它的核心定位是“被动服务”，**仅响应调用请求，不参与决策或推理**。
	> <font color = o>简单说就是一个包含了很多功能的工具箱，没有任何智能。
	> 一般说一个AI工具支持MCP模式是指：该工具遵循MCP协议，可以在AI工具中调用MCP Server 的 API。
	
	<img src="https://github.com/zeff163/stackedit-app-data/blob/master/Daily%20work/2025/picture/4.22/001.png?raw=true">
	
	 MCP Server的功能相对单一，专注于提供数据和工具接口。例如，**它可以抓取网页、读取文件或调用API，但不具备推理能力。**

	优势：模块化设计，便于独立开发和扩展。
	局限性：只能被动响应，无法主动解决问题。


+ **Function Call：微型函数**
Function Call是指大模型直接调用预定义函数的能力，允许模型生成请求参数并整合结果。例如，模型可以通过Function Call查询天气或执行简单的数学计算。**它的本质是“代码级工具”**，通常与模型绑定部署。
	> <font color = o>例如：getWeather()是一个可以查询天气的函数，那么一般的大模型都会在模型中添加该函数，方便用户使用，尽管LLM的主要功能不是查天气。与此类似的还有实时翻译等功能。
	> 和MCP Server的区别：MCP通常是工具箱级别的内容，包含复杂功能、多个函数；而FC则只是一个单一的函数，更小型轻便，而且使用频率较高，所以可以直接嵌入大模型代码中。

	<img src="https://github.com/zeff163/stackedit-app-data/blob/master/Daily%20work/2025/picture/4.22/002.png?raw=true">
	
	Function Call适合处理简单、低延迟的任务，例如实时翻译、情感分析等。**它与模型紧密集成，能够在推理过程中快速调用。**

	优势：高效便捷，无需额外通信开销。
	局限性：受模型运行时资源限制，无法执行耗时任务。

+ **Agent：自主决策的智能工人**  
Agent是一种具备自主决策能力的AI实体，能够感知环境、规划任务并调用工具（包括MCP Server和Function Call）完成目标。例如，一个Agent可以接到“撰写AI趋势报告”的任务后，自动抓取数据、分析内容并生成报告。

	<img src="https://github.com/zeff163/stackedit-app-data/blob/master/Daily%20work/2025/picture/4.22/003.png?raw=true">

	><font color = o> Agent可以看成是基于LLM的可以自主完成任务的一个工具，它具有分析推理能力，并且可以调用MCP的API来实现指定的功能，甚至都不要人为选择去调用什么API，它会根据任务需求自主决定该如何完成任务。

	Agent能够感知需求、推理规划并执行多步骤任务。例如，它可以通过调用多个MCP Server完成跨平台数据整合，或者结合Function Call实现动态调整策略。

	优势：高自主性，支持复杂流程。
	局限性：开发复杂度较高，需要集成推理框架和状态管理

**不再混淆了！一文揭秘MCP Server、Function Call与Agent的核心区别**
	https://blog.csdn.net/kaka0722ww/article/details/146112289 
	[<font color=red>PDF文件</font>](https://github.com/zeff163/stackedit-app-data/blob/master/Daily%20work/2025/picture/4.22/%E4%B8%8D%E5%86%8D%E6%B7%B7%E6%B7%86%E4%BA%86%E4%B8%80%E6%96%87%E6%8F%AD%E7%A7%98MCPServer%E3%80%81FunctionCall%E4%B8%8EAgent%E7%9A%84%E6%A0%B8%E5%BF%83%E5%8C%BA%E5%88%AB_functioncall%E5%92%8Cagent%E5%85%B3%E7%B3%BB.pdf?raw=true)  

**Agent和LLM的区别**
别再混淆了！一文看懂Agent和大模型的5大核心区别
	https://baijiahao.baidu.com/s?id=1828075208636758883&wfr=spider&for=pc
> <font color =o>Agent和LLM相比具有以下优势：
> 1. **具有更长的记忆**  <a id = "01-1">  [<font color = red>备注1</font>](#01-2)
> 2. **可以调用api**  <a id = "02-1">  [<font color = red>备注2</font>](#02-2)
> 3. **持续强化学习，获取最新知识来训练** <a id = "03-1">  [<font color = red>备注3</font>](#03-2)
> 4. **具有更好的输出效果，可以执行代码而非仅文字** <a id = "04-1">  [<font color = red>备注4</font>](#04-2)


## <font color = green>各类网站 </font>
#### 两个AI介绍主页
+ https://author.baidu.com/home?app_id=1736149104912892  
+ https://blog.csdn.net/kaka0722ww

## <font color = green>资源文件 </font>


## <font color = green>新闻 </font>
#### 微软封杀了Cursor  
https://mp.weixin.qq.com/s/XA9j3lqMck_Cr25Qu7RH_Q 
说明： Cursor基于VSCode开发，创造了一款闭源AI编程软件并进行收费，与VSCode形成市场竞争。于是VSCode限制其闭源插件无法在微软以外的软件中使用，影响Cursor用户。文中还提到了微软的限制方式，以及Cursor的应对措施。

## <font color = green>新知 </font>
+ **带下划线的学位论文标题超长，如何自动换行并居中**  
	https://mp.weixin.qq.com/s/5ea9Y8HQyiLZyq78rzFz9Q  
+ **一个新的AI工具——Trae**
	来源：[Trae最新版本发布！教你用Trae创建一个MCP Server 并调用生成一个网页](https://mp.weixin.qq.com/s/0rxMqTJzdnnXSFSRafmBvA)
	介绍：Trae 是字节出品的免费国产 AI 原生 IDE，支持 Agent 和 MCP 模式。


## <font color = green>待办事项 </font>
### <font color = purple>事项 </font>

### <font color = purple>已解决 </font>
### <font color = purple>疑问 </font>
- [ ] ...
### <font color = purple>明日计划 </font>
- [ ] 补充学习笔记
- [ ] 发型学习


## <font color = green>备注 </font>
  1. <a id ="01-2">[<font color = red>跳回</font>](#01-1) 
	  **记忆机制（会话记忆 vs 长期记忆库）**
	  
	  LLM模型的记忆机制主要体现在短期的会话记忆上，它能够记住在一次对话过程中的上下文信息，以便更好地理解用户的意图和生成连贯的回答 。例如，在多轮对话中，大模型可以根据前面的对话内容，理解用户的提问背景和相关信息，从而给出更准确、更符合上下文的回答。但是，大模型的这种会话记忆受到上下文窗口的限制，当对话轮数过多或者输入文本过长时，大模型可能会逐渐遗忘前面的信息，导致回答出现偏差或者不连贯。比如，在一个关于旅游规划的对话中，你首先询问大模型 “我想去北京旅游，有哪些景点值得去”，大模型会给出一些北京的著名景点推荐；接着你又问 “这些景点附近有什么好吃的”，大模型能够根据前面提到的北京景点，推荐一些周边的美食；但如果你继续追问 “那这些美食的价格大概是多少”，并且之前的对话已经超出了大模型的上下文窗口范围，大模型可能就无法准确关联前面提到的美食信息，导致回答不准确或者需要你重新提供相关背景信息。
	  
		Agent 则拥有更强大的长期记忆库，它不仅能够存储和检索在会话过程中的上下文信息，还可以将重要的信息长期保存下来，以便在后续的任务中使用 。在客户服务场景中，Agent 可以记录每个客户的基本信息、购买历史、咨询记录等。当客户再次咨询问题时，Agent 能够从长期记忆库中快速检索出该客户的相关信息，了解客户的历史需求和偏好，从而提供更加个性化、高效的服务。比如，一位客户之前购买过某品牌的电子产品，在使用过程中出现了问题并咨询过客服。当该客户再次联系客服时，Agent 能够从长期记忆库中获取到之前的咨询记录和问题解决方案，快速了解客户的问题背景，为客户提供更精准的帮助，无需客户再次重复描述问题，大大提高了客户服务的质量和效率。此外，Agent 还可以根据长期记忆中的信息进行学习和优化，不断提升自己的服务能力和决策水平。

2. <a id ="02-2">[<font color = red>跳回</font>](#02-1)
	**环境交互能力（封闭系统 vs 多接口调用）**

	大模型在运行过程中，主要是在一个相对封闭的数据环境中进行工作。它所处理的数据主要来源于预训练阶段所学习的大规模文本语料库，以及在实际应用中用户输入的文本信息 。大模型通过对这些数据进行分析、理解和处理，生成相应的输出结果，但它本身难以直接与外部环境进行交互，获取实时的、多样化的信息。例如，当你使用大模型进行股票市场分析时，它只能根据已有的历史股票数据、财经新闻报道等文本信息来进行分析和预测。如果市场出现了一些突发的重大事件，如某家重要公司的财务造假丑闻、宏观经济政策的突然调整等，这些信息如果没有及时被纳入到大模型的训练数据或者实时输入给它，大模型就无法基于这些最新的信息做出准确的分析和判断，因为它缺乏直接与股票市场、新闻媒体等外部环境进行交互获取最新信息的能力。

	与之相反，Agent 具备强大的环境交互能力，它可以通过多种接口与外部环境进行信息交互，获取丰富的实时信息，并根据这些信息做出相应的决策和行动 。以智能助手 Agent 为例，它可以通过调用天气 API 获取当前的天气信息，当你询问 “我今天出门需要带伞吗” 时，智能助手 Agent 能够实时获取所在地区的天气状况，包括是否有降雨、降雨概率等信息，然后根据这些信息回答你是否需要带伞；它还可以调用日历 API 获取你的日程安排，当你询问 “我今天下午有什么安排” 时，智能助手 Agent 能够从日历中读取你的日程信息，准确地告诉你今天下午的会议、约会等安排；此外，智能助手 Agent 还可以与智能家居设备进行交互，如控制智能灯光的开关、调节智能空调的温度等。通过调用这些不同的接口，Agent 能够与外部环境进行紧密的互动，获取各种所需的信息，并对环境产生实际的影响，实现更加智能化、个性化的服务。

3. <a id ="03-2">[<font color = red>跳回</font>](#03-1) 
	**学习方式（预训练 vs 持续强化学习）**

	大模型主要通过在大规模数据集上进行预训练来学习语言知识和模式，然后在实际应用中，根据具体的任务需求，可以对预训练模型进行微调，以适应特定的任务场景 。在预训练阶段，大模型会对海量的文本数据进行无监督学习，通过对大量文本的阅读和分析，学习语言的语法、语义、词汇搭配等知识，构建起一个庞大的语言知识库。例如，GPT 系列模型在预训练时，使用了互联网上的大量文本数据，包括新闻、小说、论文、博客等，通过对这些数据的学习，GPT 模型具备了强大的语言理解和生成能力。在微调阶段，针对特定的任务，如文本分类、情感分析、机器翻译等，可以使用少量的有标签数据对预训练模型进行进一步训练，使模型能够更好地完成这些特定任务。但是，大模型一旦完成预训练和微调，其知识和能力就基本固定下来，很难实时地从新的数据和环境中学习和更新自己的知识。

	Agent 采用的是持续强化学习的方式，它能够根据环境的反馈不断地调整自己的行为策略，以优化目标的实现 。以机器人路径规划 Agent 为例，假设机器人需要在一个复杂的环境中从起点移动到终点，Agent 会首先根据环境信息（如地图、障碍物位置等）制定一个初始的路径规划策略。在机器人移动过程中，Agent 会实时感知环境的变化，如是否遇到新的障碍物、路径是否畅通等，并根据这些反馈信息对路径规划策略进行调整。如果机器人发现前方出现了一个新的障碍物，Agent 会立即重新评估当前的情况，选择一条避开障碍物的新路径。通过不断地与环境进行交互，接收环境的反馈，并根据反馈调整自己的行为，Agent 能够在不同的环境中不断学习和优化，逐渐找到最优的行动策略，以更好地完成任务。与大模型不同，Agent 的学习是一个持续的、动态的过程，它能够实时适应环境的变化，不断提升自己的能力。

4. <a id ="04-2">[<font color = red>跳回</font>](#04-1)  
	**输出形式（文本流 vs 操作指令）**

	大模型的输出主要是以文本流的形式呈现，无论是回答问题、生成文章、翻译文本还是进行对话，大模型都是通过生成自然语言文本来与用户进行交互 。当你使用大模型进行文本创作时，它会根据你提供的主题和提示，生成一段连贯的文本内容，如一篇完整的新闻报道、一篇散文、一个故事等；当你询问大模型关于某个知识的问题时，它会以文字的形式给出详细的解答和说明。这种文本输出形式使得大模型在语言处理和知识表达方面具有很强的优势，但它的应用也主要局限于文本相关的领域。

	Agent 的输出则是具体的操作指令，它可以直接控制各种设备或系统执行相应的任务 。在智能工厂中，Agent 可以根据生产计划和实时的生产数据，向机器人、自动化生产线等设备发送操作指令，控制它们的动作和流程。例如，Agent 可以命令机器人抓取特定的原材料，将其放置在指定的加工位置，然后控制加工设备对原材料进行加工，完成产品的生产过程。此外，Agent 还可以与各种软件系统进行交互，如企业资源规划（ERP）系统、客户关系管理（CRM）系统等，通过发送操作指令实现数据的查询、更新、分析等功能。与大模型的文本输出不同，Agent 的操作指令输出能够直接对现实世界中的设备和系统产生影响，实现实际的任务执行和控制，在自动化、智能化的生产和管理领域具有广泛的应用前景 。
<!--stackedit_data:
eyJoaXN0b3J5IjpbLTE2MzMxMTkwMzIsMjM5NTcyOTAxLC04Nj
UyNDQ4ODksMjAyNjA4Mjg3NCwtMTc2NzI5NTMyMCwtMTA2NjY4
MDI5MSwtODAzMjc2MjIzLDE4MjY1NjU0NjldfQ==
-->